{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anama-1104/cis677/blob/main/Lab_activity_Amdahl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Activity - Amdahl's law\n",
        "\n",
        "Amdahl's law (https://en.wikipedia.org/wiki/Amdahl%27s_law) provides important insight into the limits of succesful parallelization.\n",
        "\n",
        "The key observation is that parts of the execution of a program are inherently sequential and cannot be parallelized.\n",
        "So, if the parallelizable portion of the code is parallelized in a very efficient manner, the portion of the execution time that is spent on the sequential part cannot be made faster.\n",
        "\n",
        "This lab activity is very similar to what you did for your first programming project. The problem, the minimum dominating set, is the same and the code is almost identical. The only difference is that the time required to read the file is now timed separately.\n",
        "\n",
        "For the purposes of this lab activity, we will make two assumptions:\n",
        "\n",
        "\n",
        "\n",
        "1.   The code that solves the problem can be parallelized\n",
        "2.   The code that reads the input matrix cannot be parallelized\n",
        "\n",
        "Run the programs and write down the times required to read the file and to solve the problem.\n",
        "\n",
        "Use Amdahl's law to calculate the maximum speedup for each of the three test files.\n",
        "\n",
        "Notice that the maximum speedup will be higher for the larger problems,\n",
        "that is, the maximum speedup increases as the size of the problem increases.\n",
        "\n",
        "This analysis can be useful to understand the kind of theoretical execution time improvements that can be obtained by parallelizing code, depending on the nature of the code and the size of the problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "sJwAS-j20gje"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvgRH4p9zmE6",
        "outputId": "c8e36336-65a7-4ae1-dfcb-4025f0379be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing original_python.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile original_python.py\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def read_adjacency_matrix(file_name):\n",
        "  file_object = open(file_name, \"r\")\n",
        "  # Input the number of rows and columns\n",
        "  size = int(file_object.readline())\n",
        "  rows = size\n",
        "  cols = size\n",
        "  # Initialize an empty matrix\n",
        "  matrix = []\n",
        "\n",
        "  # Input the matrix elements\n",
        "  for i in range(rows):\n",
        "    row = list(map(int, file_object.readline().split()))\n",
        "    matrix.append(row)\n",
        "  return matrix,size\n",
        "\n",
        "# Convert an integer into a set of nodes\n",
        "def convert_from_int_to_set(integer,size):\n",
        "  set_of_nodes = []\n",
        "  mask = 1\n",
        "  for i in range(size):\n",
        "    if ((mask & integer) != 0):\n",
        "      set_of_nodes.append(i)\n",
        "    mask = mask * 2\n",
        "  return set_of_nodes\n",
        "\n",
        "# Find the maximum independent set\n",
        "def find_max_ind_set(adj_mat_numpy,size):\n",
        "  max_independent_set_size = 0\n",
        "  max_independent_set = []\n",
        "\n",
        "  size_of_power_set = 1\n",
        "  for i in range(size):\n",
        "    size_of_power_set *= 2\n",
        "  # print(\"The power set has \",size_of_power_set,\" elements\")\n",
        "  array_with_sizes = np.zeros(size_of_power_set)\n",
        "  for i in range(size_of_power_set):\n",
        "    this_set = convert_from_int_to_set(i,size)\n",
        "    is_independent = True\n",
        "    for n1 in this_set:\n",
        "      for n2 in this_set:\n",
        "        if (adj_mat_numpy[n1][n2] == 1):\n",
        "          is_independent = False\n",
        "    if (is_independent):\n",
        "      array_with_sizes[i] = len(this_set)\n",
        "    else:\n",
        "      array_with_sizes[i] = 0\n",
        "\n",
        "\n",
        "  max_independent_set_size = np.max(array_with_sizes)\n",
        "  max_independent_set = np.where(array_with_sizes == max_independent_set_size)[0]\n",
        "  # print(\"The max independent sets are encoded by: \",max_independent_set)\n",
        "  return max_independent_set_size\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "# Read the content of the file with the a passed in the command line\n",
        "# that contain the matrices to be multiplied\n",
        "  start_read_file = time.time()\n",
        "  adj_matrix,size = read_adjacency_matrix(sys.argv[1])\n",
        "  adj_matrix_numpy = np.array(adj_matrix)\n",
        "  end_read_file = time.time()\n",
        "  elapsed_read_file = end_read_file - start_read_file\n",
        "  print(\"Time required to read the file in python: \",elapsed_read_file)\n",
        "  start_time = time.time()\n",
        "  max_independent_set_size = find_max_ind_set(adj_matrix_numpy,size)\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(\"Time required to complete the computation in python: \",elapsed_time)\n",
        "  # print(\"The size of the maximum independent set is: \",max_independent_set_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fne5fDyJz94s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile k16.txt\n",
        "16\n",
        "0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hz-yLC9z-vJ",
        "outputId": "43ca4ee2-636c-46ad-f9c9-ca19bb669eb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k16.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile k18.txt\n",
        "18\n",
        "0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBZ-68s90CRa",
        "outputId": "b0f3eb6a-2a9d-490e-b8c0-a80d7b0721ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k18.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile k20.txt\n",
        "20\n",
        "0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
        "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrepe3eJ0F26",
        "outputId": "6c0246f7-cf1a-4d59-edc5-6f187af66961"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing k20.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python original_python.py k16.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MWN6oDT0PA5",
        "outputId": "f5d80793-ae9e-4566-8996-77eaebcb18a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time required to read the file in python:  0.0003101825714111328\n",
            "Time required to complete the computation in python:  2.750727653503418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python original_python.py k18.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8BdCr7Q0SGZ",
        "outputId": "7f737aba-763b-4aee-c96e-70bc2263a0e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time required to read the file in python:  0.0002918243408203125\n",
            "Time required to complete the computation in python:  7.500609874725342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python original_python.py k20.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMRkNIj0X8i",
        "outputId": "0a6627fa-9d6b-4679-8934-3762cd43d6a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time required to read the file in python:  0.0003311634063720703\n",
            "Time required to complete the computation in python:  39.47301888465881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Maximum Speedup Using Amdahl's Law**\n"
      ],
      "metadata": {
        "id": "cjg7gj7s8ifX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timing Results\n",
        "\n",
        "### k16.txt\n",
        "* Time to read file: 0.000310 seconds\n",
        "* Time to compute:  seconds:  2.750\n",
        "* Total time: 2.750310 seconds\n",
        "\n",
        "### k18.txt\n",
        "* Time to read file: 0.000291 seconds\n",
        "* Time to compute: 7.500seconds\n",
        "* Total time:7.500291 seconds\n",
        "\n",
        "### k20.txt\n",
        "* Time to read file: 0.000331 seconds\n",
        "* Time to compute: 39.473 seconds\n",
        "* Total time:39.473331 seconds"
      ],
      "metadata": {
        "id": "yCH3QrUn8j-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amdahl's Law Formula\n",
        "\n",
        "**Formula:** Maximum Speedup = 1 / S  \n",
        "\n",
        "**Where:** S = (Read Time) / (Total Time)\n",
        "\n",
        "\n",
        "\n",
        "## Maximum Speedup for k16.txt\n",
        "\n",
        "1. S = 0.000310 / 2.750310 = 0.0001127\n",
        "2. Maximum Speedup = 1 / 0.0001127 =  8,872\n",
        "\n",
        "\n",
        "\n",
        "## Maximum Speedup for k18.txt\n",
        "\n",
        "1. S = 0.000291/ 7.500291 = 0.0000388\n",
        "2. Maximum Speedup = 1 / 0.0000388 = 25,773\n",
        "\n",
        "\n",
        "## Maximum Speedup for k20.txt\n",
        "\n",
        "1. S = 0.000331 / 39.473331 = 0.00000839\n",
        "2. Maximum Speedup = 1 / 0.00000839  =  119,144"
      ],
      "metadata": {
        "id": "FxDF0QcB9iRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum speedup increases as the problem size increases:\n",
        "\n",
        "k16 8,872\n",
        "\n",
        "k18 25,773\n",
        "\n",
        "k20 119,144\n"
      ],
      "metadata": {
        "id": "nPjhzYLd_glu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When looking at your results, one clear pattern stands out: the time it takes to read the file — the sequential part of the process — barely changes. It’s always around 0.0003 seconds, no matter how large the problem is. In contrast, the actual computation time, which can be parallelized, grows dramatically as the problem gets bigger: about 2.75 seconds for k16, 7.5 seconds for k18, and almost 40 seconds for k20.\n",
        "\n",
        "This means that as the problems get larger, the fixed cost of reading the file becomes almost irrelevant compared to the heavy lifting of computation. For the smaller case (k16), reading the file still accounts for a tiny fraction of the work, but by the time we reach k20, it’s practically invisible in the total runtime.\n",
        "\n",
        "This behavior reflects Amdahl’s Law perfectly: the sequential part doesn’t grow, but the parallelizable work does. So, the bigger the problem, the less the sequential overhead matters, and the more benefit we can expect from parallelization. In simple terms — small problems don’t show off the power of parallelism very well, but as the workload grows, parallel computing really begins to shine"
      ],
      "metadata": {
        "id": "yJ8zSCqj_t5p"
      }
    }
  ]
}
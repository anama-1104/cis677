{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXRs466NfdEPotO0BUE1E0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/cis677/blob/main/An_introduction_to_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An introduction to cuda\n",
        "Using examples provided by NVIDIA in their online courses."
      ],
      "metadata": {
        "id": "_qJHipzz0KqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5NPQmhE9qs0",
        "outputId": "117fadf0-9335-4318-9c58-9175fcf4fa9c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 10 16:50:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A simple example"
      ],
      "metadata": {
        "id": "TahOg75Y1POK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E8MFqWh0Fk7",
        "outputId": "5d067716-da8f-4a72-99be-7b2b92c3ac22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_gpu.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile hello_gpu.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "void helloCPU()\n",
        "{\n",
        "  printf(\"Hello from the CPU.\\n\");\n",
        "}\n",
        "\n",
        "__global__ void helloGPU()\n",
        "{\n",
        "  printf(\"Hello also from the GPU.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  helloCPU();\n",
        "\n",
        "  /*\n",
        "   * Refactor this call to `helloGPU` so that it launches\n",
        "   * as a kernel on the GPU.\n",
        "   */\n",
        "\n",
        "  helloGPU<<<1,1>>>();\n",
        "\n",
        "  /*\n",
        "   * Add code below to synchronize on the completion of the\n",
        "   * `helloGPU` kernel completion before continuing the CPU\n",
        "   * thread.\n",
        "   */\n",
        "   cudaDeviceSynchronize();\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Pm8tfqk_5g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o hello_gpu hello_gpu.cu -arch=sm_75\n"
      ],
      "metadata": {
        "id": "jbZ0Hrwc0oUb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMEVUnxb0uqq",
        "outputId": "b4c9b7a8-8e6f-4dcf-ab01-ac68adc1a598"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from the CPU.\n",
            "Hello also from the GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another simple example"
      ],
      "metadata": {
        "id": "cA8HT-8k04mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile very_simple.cu\n",
        "#include <stdio.h>\n",
        "void CPUFunction()\n",
        "{\n",
        "  printf(\"This function is defined to run on the CPU.\\n\");\n",
        "}\n",
        "\n",
        "__global__ void GPUFunction()\n",
        "{\n",
        "  printf(\"This function is defined to run on the GPU.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  CPUFunction();\n",
        "\n",
        "  GPUFunction<<<1, 1>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbkjkNfK09JK",
        "outputId": "70799759-2b3b-44ec-8987-dc70d05becf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing very_simple.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc very_simple.cu -o very_simple -arch=sm_75"
      ],
      "metadata": {
        "id": "ZK8suBTk0-66"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./very_simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMvHvLu61KFj",
        "outputId": "47b100c8-0227-480e-ea41-a6fb81577592"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This function is defined to run on the CPU.\n",
            "This function is defined to run on the GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now executing a function in parallel"
      ],
      "metadata": {
        "id": "LTkjVK-q1ciM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile first_parallel.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Refactor firstParallel so that it can run on the GPU.\n",
        " */\n",
        "\n",
        "__global__ void firstParallel()\n",
        "{\n",
        "  printf(\"This should be running in parallel.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Refactor this call to firstParallel to execute in parallel\n",
        "   * on the GPU.\n",
        "   */\n",
        "\n",
        "  firstParallel<<<5,5>>>();\n",
        "\n",
        "  /*\n",
        "   * Some code is needed below so that the CPU will wait\n",
        "   * for the GPU kernels to complete before proceeding.\n",
        "   */\n",
        "     cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_tTbsez1htz",
        "outputId": "dec41696-d744-43b5-d20e-edb36f7e8771"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing first_parallel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o first_parallel first_parallel.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "kxkQ-xdo1pXq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./first_parallel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GM-g4_X1uCD",
        "outputId": "d8079bdf-49b9-4cb2-82ad-e6210d987b58"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n",
            "This should be running in parallel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-3VkM1rO-K4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thread and block id"
      ],
      "metadata": {
        "id": "0KAJiWmGBmw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile thread_and_block_id.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void printSuccessForCorrectExecutionConfiguration()\n",
        "{\n",
        "\n",
        "  if(threadIdx.x == 1023 && blockIdx.x == 255)\n",
        "  {\n",
        "    printf(\"Success!\\n\");\n",
        "  } else {\n",
        "    // printf(\"Failure. Update the execution configuration as necessary.\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Update the execution configuration so that the kernel\n",
        "   * will print `\"Success!\"`.\n",
        "   */\n",
        "\n",
        "  printSuccessForCorrectExecutionConfiguration<<<256, 1024>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I1KJ9TqBo0T",
        "outputId": "7c20edba-17a7-479e-a85e-79ca34ed73f9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing thread_and_block_id.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o thread_and_block_id thread_and_block_id.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "qizQHtQ1BzX-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./thread_and_block_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb_UeF8HB1-K",
        "outputId": "643838b9-f707-480a-c764-73862c7efea4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A single loop\n",
        "\n",
        "1 block. This single block has 10 entries."
      ],
      "metadata": {
        "id": "78zA1XKQB9qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile single_loop.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Refactor `loop` to be a CUDA Kernel. The new kernel should\n",
        " * only do the work of 1 iteration of the original loop.\n",
        " */\n",
        "\n",
        "__global__ void loop(int N)\n",
        "{\n",
        "/*\n",
        "  for (int i = 0; i < N; ++i)\n",
        "  {\n",
        "    printf(\"This is iteration number %d\\n\", i);\n",
        "  }\n",
        "  */\n",
        "  printf(\"This is iteration number %d\\n\", threadIdx.x);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * When refactoring `loop` to launch as a kernel, be sure\n",
        "   * to use the execution configuration to control how many\n",
        "   * \"iterations\" to perform.\n",
        "   *\n",
        "   * For this exercise, only use 1 block of threads.\n",
        "   */\n",
        "\n",
        "  int N = 10;\n",
        "  loop<<<1,N>>>(N);\n",
        "  cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnIvhvxWCCNj",
        "outputId": "07cbc96e-e4e8-46a6-d53c-f6de7b24e6f8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing single_loop.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o single_loop single_loop.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "6b0iULjbCGGt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./single_loop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Q_HM9bCJqW",
        "outputId": "5f29e62f-b186-41d1-9408-cdb97f7f823c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is iteration number 0\n",
            "This is iteration number 1\n",
            "This is iteration number 2\n",
            "This is iteration number 3\n",
            "This is iteration number 4\n",
            "This is iteration number 5\n",
            "This is iteration number 6\n",
            "This is iteration number 7\n",
            "This is iteration number 8\n",
            "This is iteration number 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Block\n",
        "\n",
        "Now, two blocks. Each block has five entries."
      ],
      "metadata": {
        "id": "YArqHI35DASJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multi_block.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Refactor `loop` to be a CUDA Kernel. The new kernel should\n",
        " * only do the work of 1 iteration of the original loop.\n",
        " */\n",
        "\n",
        "__global__ void loop(int N)\n",
        "{\n",
        "/*\n",
        "  for (int i = 0; i < N; ++i)\n",
        "  {\n",
        "    printf(\"This is iteration number %d\\n\", i);\n",
        "  }\n",
        "  */\n",
        "  int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  printf(\"This is interation number %d\\n\",i);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * When refactoring `loop` to launch as a kernel, be sure\n",
        "   * to use the execution configuration to control how many\n",
        "   * \"iterations\" to perform.\n",
        "   *\n",
        "   * For this exercise, be sure to use more than 1 block in\n",
        "   * the execution configuration.\n",
        "   */\n",
        "\n",
        "  int N = 10;\n",
        "  loop<<<2,5>>>(N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeBwrZaoDCSj",
        "outputId": "b1a04512-2d3a-4532-fc3d-de8e89b2baa5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing multi_block.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o multi_block multi_block.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "6zBnkkQpDGv7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./multi_block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPI3yZfGDKdi",
        "outputId": "a09f4b0c-80dd-4730-a692-3eaaa0ea772e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is interation number 0\n",
            "This is interation number 1\n",
            "This is interation number 2\n",
            "This is interation number 3\n",
            "This is interation number 4\n",
            "This is interation number 5\n",
            "This is interation number 6\n",
            "This is interation number 7\n",
            "This is interation number 8\n",
            "This is interation number 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another example: Doubling the elements of an array\n",
        "We will double the elements in an array"
      ],
      "metadata": {
        "id": "TM4khaj7AWZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile double.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Initialize array values on the host.\n",
        " */\n",
        "\n",
        "void init(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  for (i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Double elements in parallel on the GPU.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void doubleElements(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < N)\n",
        "  {\n",
        "    a[i] *= 2;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Check all elements have been doubled on the host.\n",
        " */\n",
        "\n",
        "bool checkElementsAreDoubled(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  for (i = 0; i < N; ++i)\n",
        "   {\n",
        "    if (a[i] != i*2) return false;\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int N = 100;\n",
        "  int *a;\n",
        "\n",
        "  size_t size = N * sizeof(int);\n",
        "\n",
        "  /*\n",
        "   * Refactor this memory allocation to provide a pointer\n",
        "   * `a` that can be used on both the host and the device.\n",
        "   */\n",
        "\n",
        "  //a = (int *)malloc(size);\n",
        "  cudaMallocManaged(&a,size);\n",
        "\n",
        "  init(a, N);\n",
        "\n",
        "  size_t threads_per_block = 10;\n",
        "  size_t number_of_blocks = 10;\n",
        "\n",
        "  /*\n",
        "   * This launch will not work until the pointer `a` is also\n",
        "   * available to the device.\n",
        "   */\n",
        "\n",
        "  doubleElements<<<number_of_blocks, threads_per_block>>>(a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  bool areDoubled = checkElementsAreDoubled(a, N);\n",
        "  printf(\"All elements were doubled? %s\\n\", areDoubled ? \"TRUE\" : \"FALSE\");\n",
        "\n",
        "  /* /*\n",
        "   * Refactor to free memory that has been allocated to be\n",
        "   * accessed by both the host and the device.\n",
        "   */\n",
        "\n",
        "  cudaFree(a);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ss8FmjvAV7a",
        "outputId": "77d93d39-4fd2-4121-dcc0-24fe9de84913"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing double.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E_ZceqBs-fl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc double.cu -o double -arch=sm_75\n"
      ],
      "metadata": {
        "id": "dhF2_qnT229E"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./double"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaqD6kAGAq4S",
        "outputId": "cb304616-de95-478f-da23-166a71673e10"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All elements were doubled? TRUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to handle arrays that do not match exactly the grid?"
      ],
      "metadata": {
        "id": "pYJgasIcFe0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mismatch_grid.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Currently, `initializeElementsTo`, if executed in a thread whose\n",
        " * `i` is calculated to be greater than `N`, will try to access a value\n",
        " * outside the range of `a`.\n",
        " *\n",
        " * Refactor the kernel definition to prevent out of range accesses.\n",
        " */\n",
        "\n",
        "__global__ void initializeElementsTo(int initialValue, int *a, int N)\n",
        "{\n",
        "  int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if (i < N)\n",
        "      a[i] = initialValue;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Do not modify `N`.\n",
        "   */\n",
        "\n",
        "  int N = 1000;\n",
        "\n",
        "  int *a;\n",
        "  size_t size = N * sizeof(int);\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "\n",
        "  /*\n",
        "   * Assume we have reason to want the number of threads\n",
        "   * fixed at `256`: do not modify `threads_per_block`.\n",
        "   */\n",
        "\n",
        "  size_t threads_per_block = 256;\n",
        "\n",
        "\n",
        "  /*\n",
        "   * Assign a value to `number_of_blocks` that will\n",
        "   * allow for a working execution configuration given\n",
        "   * the fixed values for `N` and `threads_per_block`.\n",
        "   */\n",
        "\n",
        "  size_t number_of_blocks =  ( N + threads_per_block - 1) / threads_per_block;;\n",
        "\n",
        "  int initialValue = 6;\n",
        "\n",
        "  initializeElementsTo<<<number_of_blocks, threads_per_block>>>(initialValue, a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  /*\n",
        "   * Check to make sure all values in `a`, were initialized.\n",
        "   */\n",
        "\n",
        "  for (int i = 0; i < N; ++i)\n",
        "  {\n",
        "    if(a[i] != initialValue)\n",
        "    {\n",
        "      printf(\"FAILURE: target value: %d\\t a[%d]: %d\\n\", initialValue, i, a[i]);\n",
        "      cudaFree(a);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"SUCCESS!\\n\");\n",
        "\n",
        "  cudaFree(a);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhF2N2T7Fi2Z",
        "outputId": "e26a0f02-0b7b-4aa9-a5d7-70076849ccb3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mismatch_grid.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o mismatch_grid mismatch_grid.cu -arch=sm_75"
      ],
      "metadata": {
        "id": "Uy9gbqfVFv3i"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mismatch_grid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sFuYzV2F3E5",
        "outputId": "e611c21b-18dc-46cf-a3ad-3c938cb90ecd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid smaller than array\n",
        "\n",
        "What can we do if the grid is actually smaller than the array we are working on?"
      ],
      "metadata": {
        "id": "jciAq26tCzyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile small_grid.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "void init(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  for (i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * In the current application, `N` is larger than the grid.\n",
        " * Refactor this kernel to use a grid-stride loop in order that\n",
        " * each parallel thread work on more than one element of the array.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void doubleElements(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  int indexWithinTheGrid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int gridStride = gridDim.x * blockDim.x;\n",
        "  for (i = indexWithinTheGrid; i < N; i += gridStride)\n",
        "  {\n",
        "   a[i] *= 2;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "bool checkElementsAreDoubled(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  for (i = 0; i < N; ++i)\n",
        "  {\n",
        "    if (a[i] != i*2) return false;\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * `N` is greater than the size of the grid (see below).\n",
        "   */\n",
        "\n",
        "  int N = 10000;\n",
        "  int *a;\n",
        "\n",
        "  size_t size = N * sizeof(int);\n",
        "  cudaMallocManaged(&a, size);\n",
        "\n",
        "  init(a, N);\n",
        "\n",
        "  /*\n",
        "   * The size of this grid is 256*32 = 8192.\n",
        "   */\n",
        "\n",
        "  size_t threads_per_block = 256;\n",
        "  size_t number_of_blocks = 32;\n",
        "\n",
        "  doubleElements<<<number_of_blocks, threads_per_block>>>(a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  bool areDoubled = checkElementsAreDoubled(a, N);\n",
        "  printf(\"All elements were doubled? %s\\n\", areDoubled ? \"TRUE\" : \"FALSE\");\n",
        "\n",
        "  cudaFree(a);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbjPy49DEJfc",
        "outputId": "0d7b3221-d6bd-4759-e032-21f7175d1b8d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting small_grid.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc small_grid.cu -o small_grid -arch=sm_75"
      ],
      "metadata": {
        "id": "IGT-7JjGEQox"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./small_grid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PHG1QmHEkuC",
        "outputId": "02b90ed1-6ffc-4285-9709-312e3ae3968c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All elements were doubled? TRUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to handle errors?"
      ],
      "metadata": {
        "id": "hGP5o4BdE2R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile handling_errors.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "void init(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  for (i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = i;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void doubleElements(int *a, int N)\n",
        "{\n",
        "\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = gridDim.x * blockDim.x;\n",
        "\n",
        "  for (int i = idx; i < N + stride; i += stride)\n",
        "  {\n",
        "    a[i] *= 2;\n",
        "  }\n",
        "}\n",
        "\n",
        "bool checkElementsAreDoubled(int *a, int N)\n",
        "{\n",
        "  int i;\n",
        "  for (i = 0; i < N; ++i)\n",
        "  {\n",
        "    if (a[i] != i*2) return false;\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Add error handling to this source code to learn what errors\n",
        "   * exist, and then correct them. Googling error messages may be\n",
        "   * of service if actions for resolving them are not clear to you.\n",
        "   */\n",
        "\n",
        "  int N = 10000;\n",
        "  int *a;\n",
        "\n",
        "  size_t size = N * sizeof(int);\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaError_t err;\n",
        "   err = cudaGetLastError(); // `cudaGetLastError` will return the error from above.\n",
        "   if (err != cudaSuccess)\n",
        "    {\n",
        "      printf(\"Error: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "  init(a, N);\n",
        "\n",
        "  // size_t threads_per_block = 2048;\n",
        "  size_t threads_per_block = 1024;\n",
        "  size_t number_of_blocks = 32;\n",
        "\n",
        "  doubleElements<<<number_of_blocks, threads_per_block>>>(a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "    err = cudaGetLastError(); // `cudaGetLastError` will return the error from above.\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "      printf(\"Error: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "  bool areDoubled = checkElementsAreDoubled(a, N);\n",
        "  printf(\"All elements were doubled? %s\\n\", areDoubled ? \"TRUE\" : \"FALSE\");\n",
        "\n",
        "  cudaFree(a);\n",
        "\n",
        "    err = cudaGetLastError(); // `cudaGetLastError` will return the error from above.\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "      printf(\"Error: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgu4CKmsE7Zt",
        "outputId": "47b28ffb-98a3-48c7-949d-1112c7838e67"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing handling_errors.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc handling_errors.cu -o handling_errors -arch=sm_75"
      ],
      "metadata": {
        "id": "kVgsyWUuFKL8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./handling_errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zelxtjhoFPHj",
        "outputId": "100a3e62-e477-48b5-e196-21bf6b40c86f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All elements were doubled? TRUE\n"
          ]
        }
      ]
    }
  ]
}
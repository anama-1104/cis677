{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdd+um5cVn7ONJeLbC5ygc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/cis677/blob/main/Basics_of_cupy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UfAVk6bE8xB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on:\n",
        "\n",
        "https://docs.cupy.dev/en/stable/user_guide/basic.html"
      ],
      "metadata": {
        "id": "FLg59ATqFAAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cupy as cp"
      ],
      "metadata": {
        "id": "7R9j_IMbFDFY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cupy.ndarray class is at the core of CuPy and is a replacement class for NumPy’s numpy.ndarray.\n",
        "\n"
      ],
      "metadata": {
        "id": "ApA2O2G9FJpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_gpu = cp.array([1, 2, 3])"
      ],
      "metadata": {
        "id": "EKGbKJ3kFIqA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_gpu above is an instance of cupy.ndarray. As one can see, CuPy’s syntax here is identical to that of NumPy. The main difference between cupy.ndarray and numpy.ndarray is that the CuPy arrays are allocated on the current device, which we will talk about later.\n",
        "\n",
        "Most of the array manipulations are also done in the way similar to NumPy. Take the Euclidean norm (a.k.a L2 norm), for example. NumPy has numpy.linalg.norm() function that calculates it on CPU."
      ],
      "metadata": {
        "id": "_L3EO-qGFZQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_cpu = np.array([1, 2, 3])\n",
        "l2_cpu = np.linalg.norm(x_cpu)"
      ],
      "metadata": {
        "id": "3v6f5tI8Fcq3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using CuPy, we can perform the same calculations on GPU in a similar way:\n",
        "\n"
      ],
      "metadata": {
        "id": "PNBeX9qgFfcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_gpu = cp.array([1, 2, 3])\n",
        "l2_gpu = cp.linalg.norm(x_gpu)"
      ],
      "metadata": {
        "id": "pV_Fe5_AFgLQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(l2_cpu)\n",
        "print(l2_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgmXlfa7FqG_",
        "outputId": "7d124a25-7aac-4cd3-8bd8-2de7776034f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7416573867739413\n",
            "3.7416573867739413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CuPy implements many functions on cupy.ndarray objects. See the reference for the supported subset of NumPy API. Knowledge of NumPy will help you utilize most of the CuPy features. We, therefore, recommend you familiarize yourself with the NumPy documentation."
      ],
      "metadata": {
        "id": "BJzpVczqFwBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Current Device\n",
        "CuPy has a concept of a current device, which is the default GPU device on which the allocation, manipulation, calculation, etc., of arrays take place. Suppose ID of the current device is 0. In such a case, the following code would create an array x_on_gpu0 on GPU 0.\n",
        "\n",
        "All CuPy operations (except for multi-GPU features and device-to-device copy) are performed on the currently active device.\n",
        "\n",
        "In general, CuPy functions expect that the array is on the same device as the current one. Passing an array stored on a non-current device may work depending on the hardware configuration but is generally discouraged as it may not be performant."
      ],
      "metadata": {
        "id": "hOkpZ1LbF1FI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transfer\n",
        "Move arrays to a device\n",
        "cupy.asarray() can be used to move a numpy.ndarray, a list, or any object that can be passed to numpy.array() to the current device:"
      ],
      "metadata": {
        "id": "KC-cJ-QtGIJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_cpu = np.array([1, 2, 3])\n",
        "x_gpu = cp.asarray(x_cpu)  # move the data to the current device."
      ],
      "metadata": {
        "id": "Dn7za9JmGMMf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move array from a device to the host\n",
        "Moving a device array to the host can be done by cupy.asnumpy() as follows:"
      ],
      "metadata": {
        "id": "dfZ2A2HoGOgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_gpu = cp.array([1, 2, 3])  # create an array in the current device\n",
        "x_cpu = cp.asnumpy(x_gpu)  # move the array to the host."
      ],
      "metadata": {
        "id": "q8X-NFV5GWQ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use cupy.ndarray.get():"
      ],
      "metadata": {
        "id": "x-dxbfrxGZRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_cpu = x_gpu.get()"
      ],
      "metadata": {
        "id": "Eor8O6AnGbFZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to write CPU/GPU agnostic code\n",
        "CuPy’s compatibility with NumPy makes it possible to write CPU/GPU agnostic code. For this purpose, CuPy implements the cupy.get_array_module() function that returns a reference to cupy if any of its arguments resides on a GPU and numpy otherwise. Here is an example of a CPU/GPU agnostic function that computes log1p:"
      ],
      "metadata": {
        "id": "DIBRrQ04HNKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stable implementation of log(1 + exp(x))\n",
        "def softplus(x):\n",
        "    xp = cp.get_array_module(x)  # 'xp' is a standard usage in the community\n",
        "    print(\"Using:\", xp.__name__)\n",
        "    return xp.maximum(0, x) + xp.log1p(xp.exp(-abs(x)))"
      ],
      "metadata": {
        "id": "nVTNf2hSHQ7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you need to manipulate CPU and GPU arrays, an explicit data transfer may be required to move them to the same location – either CPU or GPU. For this purpose, CuPy implements two sister methods called cupy.asnumpy() and cupy.asarray(). Here is an example that demonstrates the use of both methods:"
      ],
      "metadata": {
        "id": "8Jya-tmIHWGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_cpu = np.array([1, 2, 3])\n",
        "y_cpu = np.array([4, 5, 6])\n",
        "x_cpu + y_cpu\n",
        "\n",
        "x_gpu = cp.asarray(x_cpu)\n",
        "# x_gpu + y_cpu # This would generate an error Unsupported type\n",
        "\n",
        "result = cp.asnumpy(x_gpu) + y_cpu\n",
        "print(result)\n",
        "result = cp.asnumpy(x_gpu) + cp.asnumpy(y_cpu)\n",
        "print(result)\n",
        "result = x_gpu + cp.asarray(y_cpu)\n",
        "print(result)\n",
        "result = cp.asarray(x_gpu) + cp.asarray(y_cpu)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpg4ez8fHaCw",
        "outputId": "9f8e8abe-18f8-41d4-b9dd-ed159802ff8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 7 9]\n",
            "[5 7 9]\n",
            "[5 7 9]\n",
            "[5 7 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cupy.asnumpy() method returns a NumPy array (array on the host), whereas cupy.asarray() method returns a CuPy array (array on the current device). Both methods can accept arbitrary input, meaning that they can be applied to any data that is located on either the host or device and can be converted to an array."
      ],
      "metadata": {
        "id": "bIHupLDWIHx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User-Defined Kernels\n",
        "CuPy provides easy ways to define three types of CUDA kernels: elementwise kernels, reduction kernels and raw kernels. In this documentation, we describe how to define and call each kernels."
      ],
      "metadata": {
        "id": "gKwbuqAuILiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basics of elementwise kernels\n",
        "An elementwise kernel can be defined by the ElementwiseKernel class. The instance of this class defines a CUDA kernel which can be invoked by the __call__ method of this instance.\n",
        "\n",
        "A definition of an elementwise kernel consists of four parts: an input argument list, an output argument list, a loop body code, and the kernel name. For example, a kernel that computes a squared difference\n",
        " is defined as follows:"
      ],
      "metadata": {
        "id": "zrnjW1VkIPj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_diff = cp.ElementwiseKernel(\n",
        "   'float32 x, float32 y',\n",
        "   'float32 z',\n",
        "   'z = (x - y) * (x - y)',\n",
        "   'squared_diff')"
      ],
      "metadata": {
        "id": "WASV7M7EISrg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The argument lists consist of comma-separated argument definitions. Each argument definition consists of a type specifier and an argument name. Names of NumPy data types can be used as type specifiers.\n",
        "\n",
        "n, i, and names starting with an underscore _ are reserved for the internal use."
      ],
      "metadata": {
        "id": "meIcHinuIX73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above kernel can be called on either scalars or arrays with broadcasting:"
      ],
      "metadata": {
        "id": "mwZSfBmeIdyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = cp.arange(10, dtype=np.float32).reshape(2, 5)\n",
        "y = cp.arange(5, dtype=np.float32)\n",
        "print(x)\n",
        "print(y)\n",
        "print(squared_diff(x, y))\n",
        "\n",
        "print(squared_diff(x, 5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce_Oy3UWIgHA",
        "outputId": "8975b9e5-94a6-4a38-965d-266ac6a21a5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 2. 3. 4.]\n",
            " [5. 6. 7. 8. 9.]]\n",
            "[0. 1. 2. 3. 4.]\n",
            "[[ 0.  0.  0.  0.  0.]\n",
            " [25. 25. 25. 25. 25.]]\n",
            "[[25. 16.  9.  4.  1.]\n",
            " [ 0.  1.  4.  9. 16.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output arguments can be explicitly specified (next to the input arguments):"
      ],
      "metadata": {
        "id": "2ip-4FpIJsLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = cp.empty((2, 5), dtype=np.float32)\n",
        "print(squared_diff(x, y, z))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMUTFsPvJfeJ",
        "outputId": "c0c6f67d-258c-444a-9453-02ce1c796a42"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  0.  0.  0.]\n",
            " [25. 25. 25. 25. 25.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Type-generic kernels\n",
        "If a type specifier is one character, then it is treated as a type placeholder. It can be used to define a type-generic kernels. For example, the above squared_diff kernel can be made type-generic as follows:"
      ],
      "metadata": {
        "id": "dtZ5V2BqKqX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_diff_generic = cp.ElementwiseKernel(\n",
        "    'T x, T y',\n",
        "    'T z',\n",
        "    'z = (x - y) * (x - y)',\n",
        "    'squared_diff_generic')"
      ],
      "metadata": {
        "id": "6EiJ4aTcKue6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type placeholders of a same character in the kernel definition indicate the same type. The actual type of these placeholders is determined by the actual argument type. The ElementwiseKernel class first checks the output arguments and then the input arguments to determine the actual type. If no output arguments are given on the kernel invocation, then only the input arguments are used to determine the type.\n",
        "\n",
        "The type placeholder can be used in the loop body code:"
      ],
      "metadata": {
        "id": "6tzX30LiKwt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_diff_generic = cp.ElementwiseKernel(\n",
        "    'T x, T y',\n",
        "    'T z',\n",
        "    '''\n",
        "        T diff = x - y;\n",
        "        z = diff * diff;\n",
        "    ''',\n",
        "    'squared_diff_generic')"
      ],
      "metadata": {
        "id": "1aFbjES-Kxg3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More than one type placeholder can be used in a kernel definition. For example, the above kernel can be further made generic over multiple arguments:\n",
        "\n"
      ],
      "metadata": {
        "id": "6EoZykEIKz_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_diff_super_generic = cp.ElementwiseKernel(\n",
        "    'X x, Y y',\n",
        "    'Z z',\n",
        "    'z = (x - y) * (x - y)',\n",
        "    'squared_diff_super_generic')"
      ],
      "metadata": {
        "id": "61F9DeYdK2m4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this kernel requires the output argument explicitly specified, because the type Z cannot be automatically determined from the input arguments."
      ],
      "metadata": {
        "id": "FeAkeEUEK6Hn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reduction kernels\n",
        "Reduction kernels can be defined by the ReductionKernel class. We can use it by defining four parts of the kernel code:\n",
        "\n",
        "1. Identity value: This value is used for the initial value of reduction.\n",
        "\n",
        "2. Mapping expression: It is used for the pre-processing of each element to be reduced.\n",
        "\n",
        "3. Reduction expression: It is an operator to reduce the multiple mapped values. The special variables a and b are used for its operands.\n",
        "\n",
        "4. Post mapping expression: It is used to transform the resulting reduced values. The special variable a is used as its input. Output should be written to the output parameter.\n",
        "\n",
        "ReductionKernel class automatically inserts other code fragments that are required for an efficient and flexible reduction implementation.\n",
        "\n",
        "For example, L2 norm along specified axes can be written as follows:"
      ],
      "metadata": {
        "id": "pqUFzMRtLRvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l2norm_kernel = cp.ReductionKernel(\n",
        "    'T x',  # input params\n",
        "    'T y',  # output params\n",
        "    'x * x',  # map\n",
        "    'a + b',  # reduce\n",
        "    'y = sqrt(a)',  # post-reduction map\n",
        "    '0',  # identity value\n",
        "    'l2norm'  # kernel name\n",
        ")\n",
        "x = cp.arange(10, dtype=np.float32).reshape(2, 5)\n",
        "print(l2norm_kernel(x, axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXwsP6YmLhHn",
        "outputId": "56156977-4dc3-405d-cfa3-05f3034d01f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5.477226  15.9687195]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw kernels\n",
        "Raw kernels can be defined by the RawKernel class. By using raw kernels, you can define kernels from raw CUDA source.\n",
        "\n",
        "RawKernel object allows you to call the kernel with CUDA’s cuLaunchKernel interface. In other words, you have control over grid size, block size, shared memory size and stream."
      ],
      "metadata": {
        "id": "rqxox9ifLx2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_kernel = cp.RawKernel(r'''\n",
        "extern \"C\" __global__\n",
        "void my_add(const float* x1, const float* x2, float* y) {\n",
        "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    y[tid] = x1[tid] + x2[tid];\n",
        "}\n",
        "''', 'my_add')\n",
        "x1 = cp.arange(25, dtype=cp.float32).reshape(5, 5)\n",
        "x2 = cp.arange(25, dtype=cp.float32).reshape(5, 5)\n",
        "y = cp.zeros((5, 5), dtype=cp.float32)\n",
        "add_kernel((5,), (5,), (x1, x2, y))  # grid, block and arguments\n",
        "y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRn8zMhTL2KW",
        "outputId": "842849fe-ae75-412c-fa11-64e1aec60426"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  2.,  4.,  6.,  8.],\n",
              "       [10., 12., 14., 16., 18.],\n",
              "       [20., 22., 24., 26., 28.],\n",
              "       [30., 32., 34., 36., 38.],\n",
              "       [40., 42., 44., 46., 48.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A very interesing comparison of the performance of numpy vs the performance of cupy:\n",
        "\n",
        "https://medium.com/@weidagang/cupy-faster-matrix-operations-with-gpus-in-python-7c9f9b69eb84\n",
        "\n",
        "The associated COLAB notebook:\n",
        "\n",
        "\n",
        "https://colab.research.google.com/drive/1ytAyGSOKfjQ41V48hanFTH987yCZPGnI?usp=sharing"
      ],
      "metadata": {
        "id": "424Qr_BCNzkm"
      }
    }
  ]
}